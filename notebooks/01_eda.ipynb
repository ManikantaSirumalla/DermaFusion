{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - EDA for ISIC 2018 Task 3 / HAM10000\n",
        "\n",
        "This notebook validates data quality and exploratory statistics before modeling.\n",
        "\n",
        "Checks included:\n",
        "- class distribution\n",
        "- age by diagnosis\n",
        "- sex distribution by diagnosis\n",
        "- localization heatmap\n",
        "- images-per-lesion distribution\n",
        "- sample image grid\n",
        "- missing-value analysis\n",
        "- metadata correlation analysis\n",
        "- image dimension/quality analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Project root: Colab clone is /content/DermaFusion; local may be repo root or notebooks/\n",
        "if Path(\"/content/DermaFusion\").exists():\n",
        "    PROJECT_ROOT = Path(\"/content/DermaFusion\")\n",
        "else:\n",
        "    PROJECT_ROOT = Path.cwd().resolve().parents[0] if (Path.cwd() / \"src\").exists() is False else Path.cwd()\n",
        "\n",
        "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
        "META_DIR = RAW_DIR / \"metadata\"\n",
        "MERGED_CSV = META_DIR / \"metadata_merged.csv\"\n",
        "HAM_META_CSV = META_DIR / \"HAM10000_metadata.csv\"\n",
        "TRAIN_GT = META_DIR / \"ISIC2018_Task3_Training_GroundTruth.csv\"\n",
        "GROUPINGS_CSV = META_DIR / \"ISIC2018_Task3_Training_LesionGroupings.csv\"\n",
        "\n",
        "if MERGED_CSV.exists():\n",
        "    df = pd.read_csv(MERGED_CSV)\n",
        "    print(f\"Loaded metadata: {MERGED_CSV}\")\n",
        "elif HAM_META_CSV.exists():\n",
        "    df = pd.read_csv(HAM_META_CSV)\n",
        "    print(f\"Loaded metadata: {HAM_META_CSV}\")\n",
        "elif TRAIN_GT.exists() and GROUPINGS_CSV.exists():\n",
        "    gt = pd.read_csv(TRAIN_GT)\n",
        "    grp = pd.read_csv(GROUPINGS_CSV)\n",
        "    df = gt.merge(grp, on=\"image\", how=\"left\").rename(columns={\"image\": \"image_id\"})\n",
        "    print(f\"Built metadata from ISIC 2018: {TRAIN_GT.name} + {GROUPINGS_CSV.name}\")\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"No metadata found. Put metadata_merged.csv, HAM10000_metadata.csv, or \"\n",
        "        \"ISIC2018_Task3_Training_GroundTruth.csv + ISIC2018_Task3_Training_LesionGroupings.csv in data/raw/metadata/.\"\n",
        "    )\n",
        "\n",
        "# Image dir: raw images first, then preprocessed (for Colab hair-removed layout)\n",
        "raw_images = RAW_DIR / \"images\"\n",
        "preprocessed = PROJECT_ROOT / \"data\" / \"preprocessed_hair_removed\" / \"images\"\n",
        "if (raw_images / \"train\").exists():\n",
        "    IMAGE_DIR = raw_images\n",
        "elif raw_images.exists():\n",
        "    IMAGE_DIR = RAW_DIR\n",
        "elif preprocessed.exists():\n",
        "    IMAGE_DIR = preprocessed\n",
        "else:\n",
        "    IMAGE_DIR = raw_images  # may fail later if no images\n",
        "\n",
        "print(f\"Rows: {len(df):,}\")\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Class distribution\n",
        "if \"dx\" not in df.columns and set([\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]).issubset(df.columns):\n",
        "    class_cols = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
        "    df[\"dx\"] = df[class_cols].idxmax(axis=1).str.lower()\n",
        "\n",
        "class_counts = df[\"dx\"].value_counts().sort_values(ascending=False)\n",
        "class_pct = (class_counts / class_counts.sum()) * 100\n",
        "summary = pd.DataFrame({\"count\": class_counts, \"percent\": class_pct.round(2)})\n",
        "summary\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=summary.index, y=summary[\"count\"], palette=\"viridis\")\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Diagnosis\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Age distribution by diagnosis\n",
        "if \"age\" in df.columns:\n",
        "    plt.figure(figsize=(11, 5))\n",
        "    sns.boxplot(data=df, x=\"dx\", y=\"age\")\n",
        "    plt.title(\"Age Distribution by Diagnosis\")\n",
        "    plt.xlabel(\"Diagnosis\")\n",
        "    plt.ylabel(\"Age\")\n",
        "    plt.xticks(rotation=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Sex distribution by diagnosis\n",
        "if \"sex\" in df.columns:\n",
        "    sex_dx = pd.crosstab(df[\"dx\"], df[\"sex\"], normalize=\"index\") * 100\n",
        "    sex_dx.plot(kind=\"bar\", stacked=True, figsize=(11, 5), colormap=\"Set2\")\n",
        "    plt.title(\"Sex Distribution by Diagnosis (%)\")\n",
        "    plt.ylabel(\"Percent\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Localization heatmap\n",
        "if \"localization\" in df.columns:\n",
        "    loc_dx = pd.crosstab(df[\"dx\"], df[\"localization\"])\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    sns.heatmap(loc_dx, cmap=\"magma\")\n",
        "    plt.title(\"Diagnosis vs Localization Heatmap\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Images-per-lesion distribution\n",
        "if \"lesion_id\" in df.columns:\n",
        "    lesion_counts = df[\"lesion_id\"].value_counts()\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.histplot(lesion_counts, bins=30, kde=False)\n",
        "    plt.title(\"Images Per Lesion Distribution\")\n",
        "    plt.xlabel(\"Images per lesion\")\n",
        "    plt.ylabel(\"Number of lesions\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Missing value analysis\n",
        "missing_pct = (df.isna().sum() / len(df) * 100).sort_values(ascending=False)\n",
        "missing_df = pd.DataFrame({\"missing_pct\": missing_pct})\n",
        "missing_df[missing_df[\"missing_pct\"] > 0]\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "missing_df[\"missing_pct\"].plot(kind=\"bar\")\n",
        "plt.title(\"Missing Value Percentage by Column\")\n",
        "plt.ylabel(\"% Missing\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Correlation analysis (numeric metadata)\n",
        "numeric_cols = [c for c in [\"age\", \"age_norm\", \"sex_idx\", \"localization_idx\"] if c in df.columns]\n",
        "if numeric_cols:\n",
        "    corr = df[numeric_cols].corr(numeric_only=True)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(corr, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "    plt.title(\"Metadata Correlation Heatmap\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Image dimension / quality analysis and sample image grid\n",
        "train_image_dir = IMAGE_DIR / \"train\"\n",
        "if not train_image_dir.exists():\n",
        "    train_image_dir = IMAGE_DIR\n",
        "\n",
        "image_files = sorted(train_image_dir.glob(\"*.jpg\"))\n",
        "if not image_files:\n",
        "    raise FileNotFoundError(f\"No images found in {train_image_dir}\")\n",
        "\n",
        "shapes = []\n",
        "for path in image_files[:1000]:\n",
        "    with Image.open(path) as img:\n",
        "        w, h = img.size\n",
        "        arr = np.asarray(img.convert(\"RGB\"))\n",
        "        variance = float(np.var(arr))\n",
        "    shapes.append({\"file\": path.name, \"width\": w, \"height\": h, \"variance\": variance})\n",
        "\n",
        "shape_df = pd.DataFrame(shapes)\n",
        "shape_df[[\"width\", \"height\", \"variance\"]].describe()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.histplot(shape_df[\"width\"], color=\"steelblue\", label=\"width\", bins=30, alpha=0.7)\n",
        "sns.histplot(shape_df[\"height\"], color=\"orange\", label=\"height\", bins=30, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.title(\"Image Width/Height Distribution (sample)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.histplot(shape_df[\"variance\"], bins=40)\n",
        "plt.title(\"Image Pixel Variance Distribution (sample)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3x7 sample images by class, if possible\n",
        "classes = [\"mel\", \"nv\", \"bcc\", \"akiec\", \"bkl\", \"df\", \"vasc\"]\n",
        "if \"dx\" in df.columns:\n",
        "    fig, axes = plt.subplots(3, 7, figsize=(18, 8))\n",
        "    for col_idx, cls in enumerate(classes):\n",
        "        class_rows = df[df[\"dx\"].astype(str).str.lower() == cls].head(3)\n",
        "        for row_idx in range(3):\n",
        "            ax = axes[row_idx, col_idx]\n",
        "            if row_idx < len(class_rows):\n",
        "                image_id = str(class_rows.iloc[row_idx][\"image_id\"])\n",
        "                img_path = train_image_dir / f\"{image_id}.jpg\"\n",
        "                if not img_path.exists():\n",
        "                    img_path = train_image_dir / image_id\n",
        "                if img_path.exists():\n",
        "                    ax.imshow(Image.open(img_path).convert(\"RGB\"))\n",
        "                    ax.set_title(cls if row_idx == 0 else \"\")\n",
        "                else:\n",
        "                    ax.text(0.5, 0.5, \"Missing\", ha=\"center\", va=\"center\")\n",
        "            ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verification Checklist\n",
        "\n",
        "After running all cells, confirm:\n",
        "\n",
        "- class distribution is consistent with HAM10000 profile\n",
        "- age missing values are visible and quantified\n",
        "- images-per-lesion distribution plotted\n",
        "- sample images render for all 7 classes where available\n",
        "- no runtime errors"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}